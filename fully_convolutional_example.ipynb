{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 1, 1, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 1, 1, 2)           258       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 270,754\n",
      "Trainable params: 270,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 0s - loss: 0.3808 - acc: 0.8250     \n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s - loss: 0.0093 - acc: 1.0000     \n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s - loss: 0.0023 - acc: 1.0000     \n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s - loss: 0.0010 - acc: 1.0000     \n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s - loss: 6.0849e-04 - acc: 1.0000     \n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s - loss: 5.0355e-04 - acc: 1.0000     \n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s - loss: 3.3169e-04 - acc: 1.0000     \n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s - loss: 2.5861e-04 - acc: 1.0000     \n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s - loss: 1.5693e-04 - acc: 1.0000     \n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s - loss: 1.4648e-04 - acc: 1.0000     \n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s - loss: 1.3228e-04 - acc: 1.0000     \n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s - loss: 1.2608e-04 - acc: 1.0000     \n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s - loss: 1.0861e-04 - acc: 1.0000     \n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s - loss: 8.0120e-05 - acc: 1.0000     \n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s - loss: 5.9077e-05 - acc: 1.0000     \n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s - loss: 4.9678e-05 - acc: 1.0000     \n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s - loss: 3.6701e-05 - acc: 1.0000     \n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s - loss: 3.4655e-05 - acc: 1.0000     \n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s - loss: 2.5590e-05 - acc: 1.0000     \n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s - loss: 2.5459e-05 - acc: 1.0000     \n",
      "img.shape (192, 160, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 1, 1, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 1, 1, 2)           258       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 270,754\n",
      "Trainable params: 270,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "pred_map.shape (192, 160, 2)\n",
      "img.shape (160, 128, 3)\n",
      "pred_map.shape (160, 128, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACcCAYAAACENOsLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDFJyFxHJoP8HHLye01y6fc0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5b58fc310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # Set CPU mode\n",
    "n_classes= 2\n",
    "image_size= 32\n",
    "\n",
    "#Create black and white dummy dataset, classification accuracy should be 100%\n",
    "def create_data():\n",
    "    n_samples= 40\n",
    "    neg_samples= np.zeros((n_samples,image_size,image_size,3),np.uint8)\n",
    "    pos_samples= 255*np.ones((n_samples,image_size,image_size,3),np.uint8)\n",
    "    X= np.concatenate((neg_samples,pos_samples),axis=0)\n",
    "    neg_samples_labels= np.zeros((n_samples),np.uint8)\n",
    "    pos_samples_labels= np.ones((n_samples),np.uint8)\n",
    "    y= np.concatenate((neg_samples_labels,pos_samples_labels),axis=0)\n",
    "    \n",
    "    #shuffle\n",
    "    indx= np.random.permutation(X.shape[0])\n",
    "    X= X[indx]\n",
    "    y= y[indx]\n",
    "    \n",
    "    #convert to categorical\n",
    "    y = keras.utils.to_categorical(y, n_classes)\n",
    "    \n",
    "    #Scale data\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X = (X - mean) / std\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "#Let's create cifar-like model\n",
    "#https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py\n",
    "def get_cifar_model():    \n",
    "    inputs = Input((image_size,image_size,3))\n",
    "    \n",
    "    conv1= Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    conv2= Conv2D(32, (3, 3), activation='relu')(conv1)\n",
    "    pool1= MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    drop1= Dropout(0.25)(pool1)\n",
    "    \n",
    "    conv3= Conv2D(64, (3, 3), activation='relu')(drop1)\n",
    "    conv4= Conv2D(64, (3, 3), activation='relu')(conv3)\n",
    "    pool2= MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    drop2= Dropout(0.25)(pool2)\n",
    "    \n",
    "    conv5= Conv2D(128, (5, 5), activation='relu')(drop2)\n",
    "    drop3= Dropout(0.25)(conv5)\n",
    "    conv6= Conv2D(n_classes, (1, 1), name='conv6')(drop3)\n",
    "    flat1= Flatten()(conv6)\n",
    "    act1= Activation('softmax')(flat1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[act1])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print model.summary()\n",
    "    #sys.exit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_cifar():\n",
    "    model= get_cifar_model()\n",
    "    \n",
    "    X,y= create_data()\n",
    "    model.fit(X,y,batch_size=10,epochs=20)\n",
    "    \n",
    "    model.save_weights('cifar_model_weights.h5')\n",
    "\n",
    "#Let's do sliding window classification with original cifar network\n",
    "def test_cifar():\n",
    "    img= np.zeros((5*image_size,4*image_size,3),np.uint8)\n",
    "    img[2*image_size:3*image_size,image_size:2*image_size]= 255\n",
    "    img= cv2.copyMakeBorder(img,image_size/2,image_size/2,image_size/2,image_size/2,cv2.BORDER_REPLICATE)\n",
    "    print 'img.shape', img.shape\n",
    "    \n",
    "    model= get_cifar_model()\n",
    "    model.load_weights('cifar_model_weights.h5')\n",
    "    \n",
    "    pred_map= np.zeros((img.shape[0], img.shape[1], n_classes),np.float32)\n",
    "    img_batch= img[None, ...]\n",
    "    for y in range(img.shape[0]-image_size):\n",
    "        for x in range(img.shape[1]-image_size):\n",
    "            tile= img_batch[:,y:y+image_size,x:x+image_size,:]\n",
    "            pred_map[y+image_size/2,x+image_size/2]= model.predict(tile)\n",
    "    \n",
    "    print 'pred_map.shape', pred_map.shape\n",
    "    \n",
    "    #Crop central part of padded image\n",
    "    img= img[image_size/2:-image_size/2,image_size/2:-image_size/2]\n",
    "    pred_map= pred_map[image_size/2:-image_size/2,image_size/2:-image_size/2]\n",
    "    print 'img.shape', img.shape\n",
    "    print 'pred_map.shape', pred_map.shape\n",
    "    \n",
    "    #plot original image, positive predition probs and thresholded binary\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.subplot(1,3,2)\n",
    "    pos= pred_map[:,:,1]\n",
    "    plt.imshow(pos)\n",
    "    plt.subplot(1,3,3)\n",
    "    pos[pos > 0.5]= 255\n",
    "    pos[pos <= 0.5]= 0\n",
    "    plt.imshow(pos)\n",
    "    plt.show()\n",
    "    \n",
    "train_cifar()\n",
    "test_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 1, 1, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 1, 1, 2)           258       \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 270,754\n",
      "Trainable params: 270,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 0s - loss: 0.3741 - acc: 0.8250     \n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s - loss: 0.0078 - acc: 1.0000     \n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s - loss: 0.0022 - acc: 1.0000     \n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s - loss: 8.7761e-04 - acc: 1.0000     \n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s - loss: 5.8855e-04 - acc: 1.0000     \n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s - loss: 5.1118e-04 - acc: 1.0000     \n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s - loss: 3.8460e-04 - acc: 1.0000     \n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s - loss: 3.8172e-04 - acc: 1.0000     \n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s - loss: 2.3999e-04 - acc: 1.0000     \n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s - loss: 1.5171e-04 - acc: 1.0000     \n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s - loss: 1.1453e-04 - acc: 1.0000     \n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s - loss: 9.3086e-05 - acc: 1.0000     \n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s - loss: 8.7024e-05 - acc: 1.0000     \n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s - loss: 9.9640e-05 - acc: 1.0000     \n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s - loss: 9.3409e-05 - acc: 1.0000     \n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s - loss: 5.4880e-05 - acc: 1.0000     \n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s - loss: 3.7780e-05 - acc: 1.0000     \n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s - loss: 3.0060e-05 - acc: 1.0000     \n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s - loss: 1.6231e-05 - acc: 1.0000     \n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s - loss: 2.2317e-05 - acc: 1.0000     \n",
      "img.shape (160, 128, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 160, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 158, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 156, 124, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 78, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 78, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 76, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 74, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 37, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 37, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 33, 25, 128)       204928    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 33, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 33, 25, 2)         258       \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 33, 25, 2)         0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 33, 25, 2)         0         \n",
      "=================================================================\n",
      "Total params: 270,754\n",
      "Trainable params: 270,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "pred_map.shape (1, 33, 25, 2)\n",
      "np.min(pred_map) 0.0\n",
      "np.max(pred_map) 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAChCAYAAADX50R7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5e02dcd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # Set CPU mode\n",
    "n_classes= 2\n",
    "image_size= 32\n",
    "\n",
    "#Create black and white dummy dataset, classification accuracy should be 100%\n",
    "def create_data():\n",
    "    n_samples= 40\n",
    "    neg_samples= np.zeros((n_samples,image_size,image_size,3),np.uint8)\n",
    "    pos_samples= 255*np.ones((n_samples,image_size,image_size,3),np.uint8)\n",
    "    X= np.concatenate((neg_samples,pos_samples),axis=0)\n",
    "    neg_samples_labels= np.zeros((n_samples),np.uint8)\n",
    "    pos_samples_labels= np.ones((n_samples),np.uint8)\n",
    "    y= np.concatenate((neg_samples_labels,pos_samples_labels),axis=0)\n",
    "    \n",
    "    #shuffle\n",
    "    indx= np.random.permutation(X.shape[0])\n",
    "    X= X[indx]\n",
    "    y= y[indx]\n",
    "    \n",
    "    #convert to categorical\n",
    "    y = keras.utils.to_categorical(y, n_classes)\n",
    "    \n",
    "    #Scale data\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X = (X - mean) / std\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def fc_reshape(x):\n",
    "    if(x.shape[1]==1):\n",
    "        x_new= K.reshape(x,(-1,n_classes))\n",
    "    else:\n",
    "        x_new= x\n",
    "    \n",
    "    return x_new\n",
    "\n",
    "def fc_reshape_output_shape(input_shape):\n",
    "    if(input_shape[1]==1):\n",
    "        output_shape= (None,n_classes)\n",
    "    else:\n",
    "        output_shape= input_shape\n",
    "    \n",
    "    return output_shape\n",
    "    \n",
    "#Fully convolutional version of cifar-like network that can have arbitary size input\n",
    "def get_fc_cifar_model(h,w):\n",
    "    inputs = Input((h, w, 3))\n",
    "    \n",
    "    conv1= Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    conv2= Conv2D(32, (3, 3), activation='relu')(conv1)\n",
    "    pool1= MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    drop1= Dropout(0.25)(pool1)\n",
    "    \n",
    "    conv3= Conv2D(64, (3, 3), activation='relu')(drop1)\n",
    "    conv4= Conv2D(64, (3, 3), activation='relu')(conv3)\n",
    "    pool2= MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    drop2= Dropout(0.25)(pool2)\n",
    "    \n",
    "    conv5= Conv2D(128, (5, 5), activation='relu')(drop2)\n",
    "    drop3= Dropout(0.25)(conv5)\n",
    "    conv6= Conv2D(n_classes, (1, 1), name='conv6')(drop3)\n",
    "    flat1= Lambda(fc_reshape, output_shape=fc_reshape_output_shape)(conv6)\n",
    "    act1= Activation('softmax')(flat1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[act1])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer= keras.optimizers.Adadelta(),\n",
    "            metrics=['accuracy'])\n",
    "            \n",
    "    print (model.summary())\n",
    "    #sys.exit(0) #\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fc_cifar():\n",
    "    model= get_fc_cifar_model(image_size,image_size)\n",
    "    \n",
    "    X,y= create_data()\n",
    "    model.fit(X,y,batch_size=10,epochs=20)\n",
    "    \n",
    "    model.save_weights('cifar_fc_model_weights.h5')\n",
    "    \n",
    "#Let's create image bigger than image_sizeximage_size and test FC cifar network    \n",
    "def test_fc_cifar():\n",
    "    img= np.zeros((5*image_size,4*image_size,3),np.uint8)\n",
    "    img[2*image_size:3*image_size,image_size:2*image_size]= 255\n",
    "    print 'img.shape', img.shape\n",
    "    \n",
    "    model= get_fc_cifar_model(img.shape[0],img.shape[1])\n",
    "    model.load_weights('cifar_fc_model_weights.h5')\n",
    "    \n",
    "    pred_map= model.predict(img[None,...])\n",
    "    print 'pred_map.shape', pred_map.shape\n",
    "    print 'np.min(pred_map)', np.min(pred_map)\n",
    "    print 'np.max(pred_map)', np.max(pred_map)\n",
    "    \n",
    "    #Plot original image, positive predition probs and thresholded binary\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.subplot(1,3,2)\n",
    "    pos= pred_map[0,:,:,1]\n",
    "    plt.imshow(pos)\n",
    "    plt.subplot(1,3,3)\n",
    "    pos[pos > 0.5]= 255\n",
    "    pos[pos <= 0.5]= 0\n",
    "    plt.imshow(pos)\n",
    "    plt.show()\n",
    "\n",
    "train_fc_cifar()\n",
    "test_fc_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
